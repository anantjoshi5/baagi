<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Stakeholders – Baagi</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <header>
    <h1>Stakeholders</h1>
    <p>Understanding the fears, hopes and roles of those affected</p>
  </header>
  <nav>
    <a href="index.html">Home</a>
    <a href="problem.html">Problem &amp; Vision</a>
    <a href="philosophy.html">Philosophy</a>
    <a href="approach.html">Approach</a>
    <a href="stakeholders.html">Stakeholders</a>
    <a href="services.html">Services</a>
    <a href="articles.html">Articles</a>
    <a href="contact.html">Contact</a>
  </nav>
  <div class="container">
    <section>
      <h2>Frontline Officials</h2>
      <p>Bureaucrats and police officers are often tasked with making complex judgments under pressure and with limited resources. Many see discretion as necessary to handle exceptions in rigid processes. Baagi recognises their expertise and seeks to design digital tools that help rather than replace them. When rules are codified and routine decisions automated, officials can focus on truly exceptional cases, exercise professional judgment where it is needed and spend less time on paperwork. We also invest in training and change management so that officers understand how algorithms reach conclusions and feel confident overseeing them.</p>
    </section>
    <section>
      <h2>Citizens</h2>
      <p>Citizens are the primary beneficiaries of fair, rule‑based governance. They suffer when arbitrary decisions deny permits, licences or welfare benefits, and when bias in policing undermines trust. Data from the European Union Agency for Fundamental Rights shows that people with an ethnic minority or immigrant background are disproportionately subject to searches and requests for identity papers during police stops.<sup><a href="#fn1">1</a></sup> These experiences erode confidence in public institutions. By making decision criteria public and automating their application, Baagi aims to restore predictability, reduce harassment and create simple appeal channels when decisions are wrong.</p>
    </section>
    <section>
      <h2>Policy Makers and Leaders</h2>
      <p>Senior officials and elected representatives have the authority to mandate rule‑based processes and allocate resources to digitisation. They may worry about the political consequences of enforcing rules strictly or about the risk of algorithmic bias. Research by the UK’s Centre for Data Ethics and Innovation highlights the need for transparency and accountability when deploying algorithms, calling on leaders to remain responsible for outcomes even when using automated systems.<sup><a href="#fn2">2</a></sup> By piloting projects, documenting benefits and addressing concerns openly, Baagi helps leaders champion reforms that increase trust and efficiency.</p>
    </section>
    <section class="footnotes">
      <h3>References</h3>
      <ol>
        <li id="fn1"><a href="https://fra.europa.eu/sites/default/files/fra_uploads/fra-2021-fundamental-rights-survey-police-stops_en.pdf" target="_blank">European Union Agency for Fundamental Rights, <em>Your rights matter: Police stops</em> (2021)</a> – reports that 34&nbsp;% of people with an ethnic minority or immigrant background who were stopped on foot were searched, compared with 14&nbsp;% of the general population.</li>
        <li id="fn2"><a href="https://assets.publishing.service.gov.uk/media/60142096d3bf7f70ba377b20/Review_into_bias_in_algorithmic_decision-making.pdf" target="_blank">Centre for Data Ethics and Innovation, <em>Review into bias in algorithmic decision‑making</em> (2020)</a> – emphasises that decision‑makers must anticipate algorithmic bias, ensure transparency and retain accountability for outcomes.</li>
      </ol>
    </section>
  </div>
  <footer>
    <p>&copy; 2025 Baagi. All rights reserved.</p>
  </footer>
</body>
</html>