<!DOCTYPE html>
<!-- In‑depth article: Police stops and discretion. Discusses disparities in policing across Europe and advocates rule‑based policing. -->
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Police Stops and Discretion: Lessons from Europe – Baagi</title>
  <meta name="description" content="Investigate how subjective policing harms minorities across Europe and learn about Baagi’s framework for rule‑based policing." />
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <a class="skip-link" href="#main">Skip to content</a>
  <header class="site-header" role="banner">
    <div class="container header-inner">
      <a class="brand" href="index.html" aria-label="Baagi Home">
        <svg class="brand-logo" width="38" height="38" viewBox="0 0 100 100" aria-hidden="true">
          <circle cx="50" cy="50" r="46" fill="#0466c8"/>
          <circle cx="50" cy="50" r="30" fill="#7dd3fc"/>
          <path d="M35,68 Q52,40 65,68" stroke="#fff" stroke-width="6" fill="none" stroke-linecap="round"/>
        </svg>
        <span class="brand-name">Baagi</span>
      </a>
      <nav class="main-nav" role="navigation" aria-label="Primary">
        <button class="nav-toggle" aria-expanded="false" aria-controls="primary-navigation" aria-label="Open navigation">
          <span class="hamburger"></span>
        </button>
        <ul id="primary-navigation" class="nav-list">
          <li><a href="index.html">Home</a></li>
          <li><a href="problem.html">Problem &amp; Vision</a></li>
          <li><a href="philosophy.html">Philosophy</a></li>
          <li><a href="approach.html">Approach</a></li>
          <li><a href="stakeholders.html">Stakeholders</a></li>
          <li><a href="services.html">Services</a></li>
          <li><a href="articles.html" aria-current="page">Articles</a></li>
          <li><a href="contact.html">Contact</a></li>
        </ul>
      </nav>
    </div>
  </header>

  <main id="main" class="site-main">
    <div class="container">
      <header>
        <h1>Police Stops and Discretion: Lessons from Europe</h1>
        <p class="muted">How subjective policing harms minorities and how rule‑based practices can help</p>
      </header>
      <section>
        <h2>Introduction</h2>
        <p>Police have a duty to protect public safety. One tool they use is stopping people on the street or while driving to ask questions, check identity documents or search for contraband. Such stops can be legitimate when based on reasonable suspicion. However, when officers rely on subjective impressions – or worse, stereotypes – stops become discriminatory and erode public trust. Throughout Europe and beyond, ethnic minorities report feeling targeted by arbitrary stops.</p>
      </section>
      <section>
        <h2>Evidence of disparities</h2>
        <p>The European Union Agency for Fundamental Rights (FRA) examined police stops across the EU. Its 2021 survey found that people with an ethnic minority or immigrant background experienced more intrusive stops than the general population. For example, among those stopped while walking, 34 % of minorities were searched compared with 14 % of the general population. Minorities were also asked for identity papers more often during stops.<sup><a href="#fn1">1</a></sup> Beyond the search itself, respect mattered: only 46 % of minority respondents felt the police treated them respectfully during their last stop, compared with 60 % of all respondents.<sup><a href="#fn2">2</a></sup></p>
        <p>These statistics are not just numbers – they translate into a lived experience of suspicion and unequal treatment. When certain groups are routinely subjected to more intrusive actions, they may disengage from law‑enforcement institutions, report crimes less often and feel alienated from society.</p>
      </section>
      <section>
        <h2>Why discretion can be problematic</h2>
        <p>Police discretion is necessary because laws cannot anticipate every circumstance. Yet unstructured discretion allows implicit biases to shape decisions. Officers may unconsciously associate certain ethnicities with criminality or use broad categories like “suspicious behaviour” to justify a stop. Such practices run counter to the rule of law, which demands that all persons and institutions be accountable to publicly promulgated laws, equally enforced and independently adjudicated.<sup><a href="#fn3">3</a></sup></p>
        <p>Unfair stops also expose agencies to legal challenges and reduce the effectiveness of policing. Communities that distrust the police are less likely to cooperate, making it harder to solve crimes. Moreover, discriminatory practices can be transmitted into algorithmic systems if historical data are used without critical review. The UK’s Centre for Data Ethics and Innovation cautions that algorithms can entrench or amplify historic biases and calls for transparency, bias monitoring and human accountability when automating decision‑making.<sup><a href="#fn4">4</a></sup></p>
      </section>
      <section>
        <h2>Towards rule‑based policing</h2>
        <p>To address these challenges, police agencies can adopt rule‑based frameworks for stops and searches. Clear guidelines should define reasonable suspicion and require officers to record the objective factors that justify a stop. Digital tools such as body‑worn cameras and mobile apps can capture these justifications and provide an audit trail. Supervisors can review data to identify patterns of bias and intervene early.</p>
        <p>Technology can also assist by flagging stops that deviate from the guidelines. For example, if an officer repeatedly stops individuals without documenting a valid reason, the system can trigger a review. Any algorithm used to prioritise enforcement must be transparent and subject to rigorous bias testing, consistent with recommendations from the UK review.<sup><a href="#fn4">4</a></sup></p>
      </section>
      <section>
        <h2>Conclusion</h2>
        <p>Random stops based on intuition or prejudice undermine the rule of law and harm those who are already marginalised. Evidence from across Europe shows that minorities are more likely to be searched and less likely to feel respected during police encounters. By replacing unstructured discretion with clear guidelines, transparent documentation and accountable technology, law‑enforcement agencies can protect both public safety and civil liberties. Baagi advocates for rule‑based policing that treats every person with dignity and relies on objective criteria rather than subjective hunches.</p>
      </section>
      <section class="footnotes">
        <h3>References</h3>
        <ol>
          <li id="fn1"><a href="https://fra.europa.eu/sites/default/files/fra_uploads/fra-2021-fundamental-rights-survey-police-stops_en.pdf" target="_blank">European Union Agency for Fundamental Rights, <em>Your rights matter: Police stops</em> (2021)</a> – finds that 34 % of people with an ethnic minority or immigrant background who were stopped on foot were searched, compared with 14 % of the general population.</li>
          <li id="fn2"><a href="https://fra.europa.eu/sites/default/files/fra_uploads/fra-2021-fundamental-rights-survey-police-stops_en.pdf" target="_blank">European Union Agency for Fundamental Rights, <em>Your rights matter: Police stops</em> (2021)</a> – reports that only 46 % of minority respondents felt the police treated them respectfully during their last stop, compared with 60 % of all respondents.</li>
          <li id="fn3"><a href="https://www.un.org/ruleoflaw/what-is-the-rule-of-law/" target="_blank">United Nations, <em>What is the rule of law?</em> (2023)</a> – states that the rule of law requires laws to be publicly promulgated, equally enforced and independently adjudicated, avoiding arbitrariness.</li>
          <li id="fn4"><a href="https://assets.publishing.service.gov.uk/media/60142096d3bf7f70ba377b20/Review_into_bias_in_algorithmic_decision-making.pdf" target="_blank">Centre for Data Ethics and Innovation, <em>Review into bias in algorithmic decision‑making</em> (2020)</a> – warns that algorithms can entrench or amplify historic biases and calls for transparency, bias monitoring and human accountability when automating decisions.</li>
        </ol>
      </section>
    </div>
  </main>

  <footer class="site-footer" role="contentinfo">
    <div class="container footer-inner">
      <div class="footer-brand">
        <strong>Baagi</strong>
        <p class="muted">Design for community systems</p>
      </div>
      <nav class="footer-nav" aria-label="Footer">
        <ul>
          <li><a href="index.html">Home</a></li>
          <li><a href="articles.html" aria-current="page">Articles</a></li>
          <li><a href="contact.html">Contact</a></li>
        </ul>
      </nav>
      <div class="legal muted">
        <p>© <span id="year">2025</span> Baagi. All rights reserved.</p>
      </div>
    </div>
  </footer>
  <script>
    (function () {
      const btn = document.querySelector('.nav-toggle');
      const nav = document.getElementById('primary-navigation');
      btn.addEventListener('click', () => {
        const expanded = btn.getAttribute('aria-expanded') === 'true';
        btn.setAttribute('aria-expanded', String(!expanded));
        nav.classList.toggle('open');
      });
      const yearElem = document.getElementById('year');
      if (yearElem) {
        yearElem.textContent = new Date().getFullYear();
      }
    })();
  </script>
</body>
</html>